{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deepmind marked the year 2017 by creating the best Go player in the world. How did they achieve this? With deep learning, of course, but more precisely with reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Blue beat human chess players with traditional game analysis. But this was not possible with Go, which was never solvable by computers until Deepmind created their network and its training methods. Because without training, the network is useless!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook, will include the following:\n",
    "* Look at different types of reinforcement learning\n",
    "* Explore the concept of Q-learning\n",
    "* Estimate a Q function via a table and via a neural network\n",
    "* Make a network play an Atari game using Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforcement learning is part of the unsupervised learning space. This only thing that it can be done is to use the network, and if the network gets a good result, then it is used to enhance the model with backpropagation. Otherwise, try some more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach can also be used in finance to optimize a portfolio; this can also be used for robots. In the past, people use genetic algorithms to train a walking robot, but now reinforcement learning can also be used for this task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are neural networks that can come to the rescue. Look at a few of the main types of networks that have been given attention in the last few years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy and value network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with solving Go. At each turn, the player places one of their stones (either white for the first player or black for the second) on the board, possibly changing the color of other stones in the process, and the games ends with whoever has the most stones of their color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue is that the board is quite big, 19 x 19 squares, meaning that at the beginning there is a very big set of possible options. Which one leads to winning the game?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For chess, this was solved without neural networks. For Go, it's not possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter deep learning. For Go, different possible moves still need to be analysed, but it won't try to be as exhaustive as in chess; Monte-Carlo Tree Search (MCTS) will instead be used. This means that a random uniform number will be drawn and from this number one move will be played. This is done for several moves in advance and then assess whether it is closer to winning or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as it was seen before, it can't measure this is Go, so how is a move selected for the search and how it can be decided if it is winning or losing? This is why there are two networks. The policy network will provide the probabilities for the next move, and the value network will provide one value—either it thinks it is winning or it is losing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined together, it is possible to generate a set of possible moves with their odds of success, and they can be played. At the end of the game, the information is used to reinforce the two networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, the new AlphaGo Zero merged these networks together. So it doesn't have to have a dichotomy for such problems, as it is possible to design an architecture that does both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, Deepmind started making a name for themselves before Go. They were using what is called a Q-network to solve Atari games. These are a set of simple games where the gamer can play only up to 10 moves at each stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these networks, the goal is to estimate a long-term reward function (like the number of points) and which move will maximize it. The reward function is the following:\n",
    "# ![Reward function](./Reward%20function.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r is the reward, γ is a discounting factor (future gains are not as important as the immediate reward), s is the current state of the game, and a is the action we could take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, as it is continuously learning, it is also continuously forgetting, and the network will have to be fed with past training as well. To use a metaphor, it will end up running without being able to walk, which is quite useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excelling at games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remainder of this notebook, Q-games will be used with the gym package. It offers a standard API for playing different types of games, so it's the perfect test case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A small example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anaconda doesn't ship this package, so it has to be installed though pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Atari part of the gym won't be used, but it will be required for the breakout game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this package, an environment can be created for different games, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('FrozenLake-v1')\n",
    "# env = gym.make('FrozenLake-v1', render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a new environment for the text game FrozenLake. It consists of four four-character strings, starting with S and ending up at G, the goal. But there are holes (H) on the way to this goal, and ending up there makes you lose the game:\n",
    "* SFFF\n",
    "* FHFH\n",
    "* FFFH\n",
    "* HFFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the environment, env.observation_space.n, the size of the observation space can be obtained which is 16 here (where the player is located) and the size of the action space env.action_space.n, which is 4 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a small toy example, an estimation of Q(s, a) can be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "# Set learning hyperparameters\n",
    "lr = .8\n",
    "y = .95\n",
    "num_episodes = 2000\n",
    "# Let's run!\n",
    "for i in range(num_episodes):\n",
    "    # Reset environment and get first new observation (top left)\n",
    "    s = env.reset()[0]\n",
    "    # Do 100 iterations to update the table\n",
    "    for i in range(100):\n",
    "        # Choose an action by picking the max of the table\n",
    "        # + additional random noise ponderated by the episode\n",
    "        a = np.argmax(Q[s, :] + np.random.randn(1, env.action_space.n) / (i + 1))\n",
    "        # Get new state and reward from environment after chosen step\n",
    "        s1, r, d, _, _ = env.step(a)\n",
    "        # Update Q-Table with new knowledge\n",
    "        Q[s, a] = Q[s, a] + lr*(r + y*np.max(Q[s1, :]) - Q[s, a])\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content of the table Q can now be displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.35353103e-01 2.84779089e-01 2.23429867e-01 2.12372557e-01]\n",
      " [1.88241401e-01 4.52001808e-02 1.80317684e-01 2.18930039e-01]\n",
      " [2.28871423e-01 1.75582941e-01 2.14385818e-01 2.12904816e-01]\n",
      " [7.22573763e-03 2.40670417e-02 3.39415749e-02 1.91968138e-01]\n",
      " [3.23488676e-01 3.15051830e-01 4.75992334e-02 2.75157380e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.89037491e-02 1.87592179e-04 4.54057436e-02 1.61117631e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.96062910e-01 7.93530464e-02 7.27409368e-02 6.02012156e-01]\n",
      " [1.28748559e-01 7.34690744e-01 3.35043865e-02 1.82422165e-02]\n",
      " [9.18763811e-01 5.14144201e-03 3.51944512e-02 4.54669877e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.13667164e-02 6.32686398e-02 9.15365227e-01 6.92923602e-02]\n",
      " [1.04707356e-01 9.99730825e-01 1.90092743e-01 2.20898147e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the entries that have 0 can be seen in some of the rows; these are the holes and the final goal stage. Starting from the first step, go through this table to a next step with probabilities given by these rows (after normalization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this is not a network, so use Tensorflow to make a network learn this table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tensorflow for the text game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of the type of architecture which is needed here. There is the state of the game as the input, and the goal is to make one of four values as the output. The game is simple enough that there is an optimal strategy, a unique path to get from the start to the goal. This means that the network can be very simple, with just one layer and a linear output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y = 0.99\n",
    "e = 0.1 # 1 in 10 samples, a new action was chosen for the network\n",
    "num_episodes = 2000\n",
    "learning_rate = 0.1\n",
    "\n",
    "inputs = tf.keras.Input(shape=[None, 16], dtype=tf.float32, name=\"input\")\n",
    "Qout = tf.keras.layers.Dense(units=4, use_bias=False, name=\"dense\", kernel_initializer=tf.random_uniform_initializer(minval=0, maxval=.0125))(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=Qout)\n",
    "# The optimizer will try to optimize\n",
    "trainer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "def train_step(inputs, nextQ):\n",
    "    \"\"\"Trains `net` on `example` using `optimizer`.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        Qout = model(inputs)\n",
    "        loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
    "    variables = model.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    trainer.apply_gradients(zip(gradients, variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training, it is needed to reintroduce new options, like the randomness that had been in the table before. To accomplish this, for every 10 predictions, a random action is sampled (this is called an epsilon-greedy strategy, and a variation of it will be reused later with the Atari games). Otherwise, the actual Q value is computed and the network is trained to match this result (updating the dense layer weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of succesful episodes: 39.25\n"
     ]
    }
   ],
   "source": [
    "jList = []\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    s = env.reset()[0]\n",
    "    rAll = 0\n",
    "    for j in range(100):\n",
    "        targetQ = model(np.identity(16)[s:s+1]).numpy()\n",
    "        a = tf.argmax(targetQ, 1).numpy()\n",
    "        # randomly choose a new state\n",
    "        # that may have not been encountered before\n",
    "        if np.random.rand(1) < e:\n",
    "            a[0] = env.action_space.sample()\n",
    "        s1, r, d, _, _ = env.step(a[0])\n",
    "        # Obtain the Q' values by feeding\n",
    "        # the new state through the network\n",
    "        Q1 = model(np.identity(16)[s1:s1 + 1])\n",
    "        # Obtain maxQ' and set the target value for chosen action.\n",
    "        targetQ[0, a[0]] = r + y*np.max(Q1)\n",
    "        # Train the network using target and predicted Q values\n",
    "        train_step(np.identity(16)[s:s+1], targetQ)\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            # Reduce chance of random action as the model is trained.\n",
    "            e = 1 / ((i // 50) + 10)\n",
    "            break\n",
    "    jList.append(j)\n",
    "    rList.append(rAll)\n",
    "env.close()\n",
    "print(\"Percent of succesful episodes: {}\".format((sum(rList) / num_episodes)*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this strategy, the layer gets around 40% success, but this value is biased. If we plot the evolution of the reward (averaged through time over 20 episodes), the network improves\n",
    "drastically over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABJSklEQVR4nO2deZgU1bn/v29VzwzDAMMyyA6DLCKILA7irjEuoFGjSYyaG5eYa7w35iY3q2bxqtlM8ks0uZpFExPNjTFqTIJb3OKOKKMsCggMMMg6DMMwDMzaVef3Ry19qrqquqr3bt7P88wz3dWn6pw63fXWW+95FxJCgGEYhil9lEIPgGEYhskOLNAZhmHKBBboDMMwZQILdIZhmDKBBTrDMEyZECtUx3V1daK+vr5Q3TMMw5Qkb7/99l4hxEivzwom0Ovr69HY2Fio7hmGYUoSItrq9xmbXBiGYcoEFugMwzBlAgt0hmGYMoEFOsMwTJnAAp1hGKZMYIHOMAxTJrBAZxiGKRNYoDMMc1jx/SfX4osPrcDO/d0AgKVNe/H3FTsiH0cIgUcat6E3rmV7iGlTsMAihmGYfNPR3Y97X90CADiybhC+eNY0XPHbNwEAF80dCyIKfaxn1rTga4+uxqbWQ7hx8YycjDcqrKEzDHPY0K/pnq8BQNOjFfs50NMPANh7sDfzgWUJFugMwxw26JLQ1lzV2tzvSxEW6AzDHDbEZYHu0sijaujFCAt0hmEOGzQW6AzDMOWBLvwFuq67W5ceLNAZhjlsCDK5xMtAorNAZxjmsCGri6Jm82JaS2WBzjDMYYNDQ9cOUxs6ES0iovVE1EREN3p8PpGIXiSiFUS0mojOy/5QGYZhMkML0tCjCnQzBilCLFLOSSnQiUgFcDeAxQBmAriciGa6mn0bwMNCiHkALgPwy2wPlGEYJlPkRVH9MF0UPR5AkxBisxCiD8BDAC5ytREAhpivawHszN4QGYYpJHc+vwFff3SV/f7rj67C5x98pyBjae3sxSk/+hc2tx5Ma/9XN+61Xy/d1IafPbvefr/4569gT2cP+uI6Lv7l6/jGo6sDj/XCuhYAwOOrwom7P7/1ARbd+Qr2d/WlMfJwhBHo4wBsk95vN7fJ3ALg34hoO4CnAHzB60BEdB0RNRJRY2traxrDZRgm39z5/EY83Ljdfv9w43Y8uXpXQcby9Hu7sL29G79/vTmt/a1wfQAYVlOJX/yryX5/qE/D2p0HsL+rDys+2I+/NG7zOoRNhWqIz6NGDw7V90+eWY/3d3die3t3GiMPR7YWRS8H8AchxHgA5wH4IxElHVsIcY8QokEI0TBy5Mgsdc0wDBMOXRcYWKli0azRSSYXi7DeLpb5JqwJPW7mjsnl4msYgb4DwATp/Xhzm8y1AB4GACHEGwAGAKjLxgAZhmGyRVwXUImgKuTrdx5W4MZNL5l4RAEdtX0Uwgj05QCmEdFkIqqEsei5xNXmAwAfBgAiOhqGQGebCsMwRYWuCygKQVEIfnI1rEC3NPSoGreeQ8f1lAJdCBEHcAOAZwCsg+HNsoaIbiOiC81mXwHw70S0CsCfAVwtRDG52zMMwxjmlJhCiCnkK4jDCmirXVQBnUuTS6gCF0KIp2AsdsrbbpZerwVwcnaHxjBMMSOEiFQQohjQLA2dvAW6EOEFtGU6iWpCKbQNnWEYJolSjKzUbBu69/jjuggtoC3B77e4GjSGXMECnWGYtCjFghCaDqgKQVUUz/Fruohscok6D7mcNxboDMOkRWlq6Lop0L3HrwsROmLUFuhaRIEesX0UWKAzDBMaEZBPPD/9m/+RXt+aMDV0Hxt6XBcODTrItyOqhm61Yg2dOezZd6gPB3vjKdu1H+pzRAOWGx1d/ejojn5+O/Z3Y1PrQezp7EF3n5ZW3z39GlZt77Dfd6V5HD+8vruDvXE07TmIDS2dWLa5Dcub92XUd2tnDxQCVEXxnMeNLZ1oNPsAgFc27kVPv4aefg3PrW3Bzv1GlKemC3su9nRGKxLd2Lwv8EaRCaG8XBim0Mz/7nOoG1SJxm+fHdhu3nefQ0whNP2gPBN+zrntWQBA8+3nR9rvtB+/aGuUcycMxd8/H90p7UsPrcQ/1+y233/n7+/hnisbIh/Hj3nffQ6VqoIN318s9bkCz6/bk9R2276utPrY1HoICgFDqr1F3/9KqQAA4Kr73sIXPzwN97662b6JNN9+Pn78z/ft+RQCONQbR01VsDitqYyhsyeOe1/dgo8cOxZzJgxN6xyCYA2dKRn2HgyX1CiXkXilimxeWLltf1rHWLppr+P9s2tbMhmSJ32a04DtJcwB4Mi6QWkdf3BVDFOPGITrT5+C+hEDAQAnHjkCT/7XKfj9NQvsdlefVG+/7uyJJz0RvLzBGTfZ3Z/6iWHUkCrHMXMBC3SGYUJRTIug6d60NSFQN6gKAypULJw8AgBQXzcQs8bW4kNHHWG3Wzh5eGKfEKukYeZGtp3nqtwdC3SGYUJRTG6K6YbPW37oAKAo5n+P4CjrMyDceYcS6JIMz1X4Pwt0hmFCUUwFINJ9WtB1AdUU1jHXfxl5m+Zx3m55HGY8jnqmOZpLFugMw4QiV2aCdEhXoMclgW79VzwEukND9zjvdMrXyfMXxoyTDizQGYYJRRGZ0NPX0IVIMrWoHiYXeZuXNu0O9w9jlpF3YQ2dYZi0iJprpBRI156v6SJhalFNga4Gm1y87N1W/1a7MHMs34R4UZRhmLQopsXMbJGJycXSzIM0dNnk4vaoEULYxS0ss00Yrxt5zLwoyjBMWhSTu2G2yMaiqFkS1H4vI29LMq/owhbIVrtwXi68KMowTIbkskJOoUjbbVEkTC5uTV1GdSyKJtvLrW1WuzDj0Rx5cNjkwhymxNNQZ773xFr8873CVKYPyyON2/DE6p057yfIHLB+dyduWbIGHV3e+WFSaZ43/+M9z+2vbGjFS+u9ozy9iJrbJB4yY+E7H7Tbc6zpAj39um1OsUS2p0CXtsnpDgCgpaPXzt9SYar5qUwu63YdQKuU84U1dOawZWsaeTt++9oWXP9/7+RgNNnja4+uxg0Prkhr366+8KHjXgt2PWao+h3PbcAfljbj7Q/2JbUBgA9SzP0Db2z13H7lfW/h6t8vDz3GlgPRElyFXRe45JdL7Tne3m6cS3/ckKbH1Q/HpBEDMW/i0KT9jhhShY8cOwYe1hgs29xmv77qxHoAqRdF/7HSeeOursyN6GWBzhQ95WgDzpQoc+KX9xuAncHST2P0Mw3cdcW80P2HIazXR/Pt5+PkqSPS8tyxtOjZ42sBAKdPH4mXv/YhnDZ9ZFLb4TWVuOuK+dj8w0QStI8fNx5AIt/MNxbNwIL6YQBSfx+arqOmUkXz7eej+fbzcfG88ZHHHwYW6EzRE/bx+nAiU4HuNhH4CW4/UwLBQ3XNgCjnoxCllcvFbfcOwsvzpTJmiMs+U8NXlYQ3TKrxx3XhGcCUbVigM0VPOS7qZUokge4xf8meG9H6SbfAhB9RzkdVKK3fhC3QQxS29hL6FeY2S0NXiBJeLinGI3vX5BIW6EzRE7po72FkmokiAL2ecNxz6mfyyJe5K0o/MYXSemqLoqFTCA09plBoP/S4FNCUS1igM0VP6KK9h5EmH+VcvbRZ983PT+P1m/usm1w8+vfzfFEoQw09TcFqCfR+zTK5kK3tp1ImdCE8vWmyDQt0pugJe/GW++KpM1tfZjb05ORSPn3m6SbpvXDr3TametcDTdmHyEygq4rbhq6EDizS2OTCMAZhH6/LXaA7A1MyXBQ159RSGn0XRUPMfTbqY3ov3HqPSfEp8By2j7QFujlZvdKiaFiBHmeBzjAGoTX0Mje5aOlq6F4mF3Ob9ZHvomiWijukcww/T0ZVobS+6yiLot79Gv/7eVGUYdInrMAo90VR+cYWxRTiaXIJmf41jHt4Nm6kQRkN3ahKehq6nqmG7jK5xFQKb3IR6d9IosACnSl6wl68pVQcOh0zhXx+Uc41SKDbJhcfFT1MwE82NHQv047mY+5R0zC5CCHsOUtfoBv/HW6LFNaGrufFDz2W8x4YJiJb9h7COXe8jJOn1mF7e7dD+B3qjaOmyvtn+9aW5PD1h5dvw6ULJgT219OvYcZ3/gkA+NWn5mPx7DGRx/yPlTvwxYdW4pvnzcB1p00JbLu0aS+u+O2b9vutbYcwaURN4D6PNG7D1x5dbb9fdOeraL79/IA9EngJm7PveMXx/pbH1+KWx9c6ti2aNTopj4nFoAGJ72Dmzc9gyQ0n49jxQ7FmZwfO/8Vr9mfH/M8zeO/Wc1OO75P3LLPfCyFARNh1oNvZp/m9CwC7OnrQr+l2LhUvbn18jf1aFwmNP13BOmxgJQBnGH+F6fny5YdX4ZL5/tGfch72XMIaOlN0bG/vQr8m8NL6VjTtOYhNrYfsz9q7+nz3azuYnA/kZ89tSNlfR3ciMdWm1oMRR2vut8fYb0NL6v1X7+hwvN/R3u3TMsGdz29Ma1xA+p4qfsL80obxOG1aHX5/9QJ72xJTyD2x2pkQzUotEES/6+nAuv9YCcOOmzQMNy2egX9+6VQAQE2lCgDo6tMCj/tI43b7taYL2+QSJFhf/OoZ+NNnFzq2Pfy5E3HW0aPwsfnjMfWIQfb28cMGYmztAIytHQAg+KlL09ltkTlMCTInBD3aWvtdMn+cvS2MMEvXlOF1jHTMD7k2FWUzdcKUkTX48cfngIjwoRlHhNonlXnJ/R1ZZh5rLr927lH43OlTMH7YQADA5Loax+dh0PSEySVIsE6uq8HJU+sc246fPBy/vaoBikJYNGu0vb22ugJEhE8umGieR3D/vCjKHJYELW4GXcSahwYWRqDL/aW7sGo9zmfiH50rsnn8dIRSqilxz5lltvfzG49SVMLuQ4iMF0UBp7nGXSgj8LcpMus3LCzQmaIj6MIIEtCJKjKJn3XkSjJpCj9LWKSzf7o3kbALq9mspSDPbVhSfQfu8blvjskC3RhDqpu1PD+aLpLqgKaDvG/MFuipx6PpOgt05vAkjFkl6DN5nSyMOSOrJpc0zBvp9hne+yd7Ej1gDdKX1EE3zvFZc+jnN26NIdW8yZ9qeqLKUCbeJrJQVlwaeipTIbstMoclQVpuoPbuIQDCaL8O/+40hWshNPSwfWUzfD8doZRqnElpCFJo6ErI/CnuQKxMA4vkvuXjKCFcF3WdTS7MYUqqC8N/P+O/w+QSMdIx3dJgVj9RbyDyvlEJq3hns9xZOkIpssnFbO8uxGwRU8PnT7H78KgDmg4xDxu6tS3ou4+zyYU5XAk2ufhLJysfiXzdRK/Gnp70s44RxnziNsukG5gT1pSSzYLEuRDoSSYX11z6aehhUtbKr7Mh0L0XRVOPRxOZmXrCEkqgE9EiIlpPRE1EdKNPm0uJaC0RrSGiB7M7TOZwIt1FUU0YrmFyi1ACNguLom6tMrBtUqbD1Pt4LYAWQkP3c/mzRud1+pkuirr7tARoFFOSLi2KZiLQVZJfmyaXEOPRdD0vgUUpI0WJSAVwN4CzAWwHsJyIlggh1kptpgG4CcDJQoh2IgrnoMowHgRq6AGLjl4Z7cJc83GHhp7ZomgYn293H+kvxIaT1NldFM2Dhu5aFHULQut9FP/6bGnoqrQqbFn2YmE0dD3Y/z1bhNHQjwfQJITYLIToA/AQgItcbf4dwN1CiHYAEELsye4wmVJi7c4DeHbNbry4fg9WbtsPwNAw39zcFsrVLnBRNMht0fQkcF82j6/aiUMBEYvvbt9vvw6qct/Tr+GFdS2OyMa+uI4X1rXgtY17AQDLtrSltKM3Nrc73t/1rybc+fwG/P71LXh3uzOKNK4Zx9/Z0ZN0nFaPyFgv2g/5R9dGxU8YWvPmJbNSPfW864qctd5bqRx8F0XN4zbt6cQL61ocv63Xm/Y6x5ClRVF5X3Itih6QIo5l3t3egf1dfWl5CEUlTBfjAGyT3m83t8lMBzCdiF4nomVEtMjrQER0HRE1ElFja2treiNmip7zfvEqrvvj27jm98vx0btfBwA8s2Y3PnnPMvzpzQ9S7h8kEFMtisYUwvRRgx3bv/DnFfj7yh2+fck5TNoO+gu/vyzfhmvvb8STUnj731Zsx7X3N2JPpyFchQDW7DzgP0gAb2xuc7z/YF8X7nx+I259fC0uuOs1x2cvrW/Ftfc3eh5n0Z2vBvaTOH4itcDCycND7ePHhXPGem5fZd64B3nk2Ul1g/viQysd7z//4DsQQuCh5YbYSbUo+snfLMO19zdia5txU+ns6cenpFw5gGtRVE1foB8xuMp+XWlK6NrqCgDAyxu8Zdr1//c2dnX0YKS0b67I1j0jBmAagDMAXA7gXiIa6m4khLhHCNEghGgYOXJklrpmSoFtplBp3nsoRctUvubBi6KKQrh0wQQ0fvssDDRzfgBAt0/eD7kvokSZMS+2txsCY09nQlveuT/x+qyjDUtjd79/jhFLuH1q4US8+NUzfNtZ7PPQru+9siHlfjIVMUOAbfjeYnz/4mMi7Wvx9rfPwvJvnYVPNHgnOrPmurrC+P/sf5+GH31sNoDwJqVHrj/Rfi3vkmpRtM2cI2vee/oTv5FzZo4y2mrZ0dDPmjkKy276MN7/7iL7t3LKtLrAfbr7NXx07ljcemF6cx+FMAJ9BwD5WxxvbpPZDmCJEKJfCLEFwAYYAp5hIpPpoigA1A2qsrPjBe0nbx9aXZFRKlirv+AQcOOz0UMGYKip2UVlxKDK1I0kdF1gYKWKypiSVqQnYGRXDKNhWvM5unYABpjCPeyc1krzIe8TdlHUa2F6iHlMXWRnURRwnps8Pr/z1HSBoQMri8ZtcTmAaUQ0mYgqAVwGYImrzd9haOcgojoYJpjN2RsmczgR7C3gv5/mCt6QX/tW5JEuwgpVyUigWxpb8PgTj/3pPvpH9ZaQ5yVdT4tYyBuBvJAZCxmibyF/X/I+7jH75XLRXd4xQOI7kbMtZluwpvJD1/X8ZFoEQgh0IUQcwA0AngGwDsDDQog1RHQbEV1oNnsGQBsRrQXwIoCvCSHavI/IMMEEewsEm1zkx2mnQPcr4OC8+LMh0MNki1Sl4ghRiSoc5Dwi6fpCh91Nzmhoh8SH9EaR50OeQ/eY/YpKeGW8tOzccV0qcJFl4ZrKD93wvspql76EKnAhhHgKwFOubTdLrwWAL5t/DJMRwdkW/fdza+jOAKPUfVWqSkaZCS3hETh+6bE/XU0xskAXiTwi6QozCrmfrAW7vVFS4bwBC8/t8vvkLI3+GrouZVvMdoAPEYHI/zwNU2B+JDpHijI5J2qukkChnSLbonzxx0KkAJC3V8aUjOqSyo/3vmPUMxfoUZFvdLnu075hEYUO0bfwE+i+JhcfG7rjO1UT34kmclc1KBZQ51TPo4bOAp3JOVEDZ1KZVYL68cqGF7SfW5vLpNiE/HgfNEbAFOh+UZdZzo8um1xyLtB1ASJj7sOG6FvIY4tLd3W/RVG/FAp+NvS4LnIWfq8E1DmN6/nJtAiwQGfyQNRsf8HZFgP60YXDzCJrRWEXRTPR0CtCLIraj/1EvsIlgyF4Ikcp5lqwyGlio4boy4K7T/rC/NwWU2VpBGDXHLUWRXN1/qqPhp54ImOTC1MmRF1oTCW0g/qRzSzyReRr38yBDT2M22LQo787S2Cm6ELY5o9MgmqCsEYpu45GrSwkz0lfXNbQXe1Ub6+SQA1dCDvwLBeoCnn+dhJrJjnpNgkW6EzOyabJJZU5w5ENT7p2/Twt3Bd/NrxcwuSiCXr0z0ayMEefeuaLoqmwXQY1SaCHyBMuI8+JrKG7F2RVH1NOoEDXhB14lgv8NPRsFNWIQigvF4YJw9tb2/Hw8m1J2xf+4Hk7ek8AeOCNZvzzvd3Y1t6Fz5w8GdecPNnRPp1F0Z5+Dc+va8Ex44bY29qkKEs/Tff5dS326wpVwd6Dffjvv6zEHZ+cm9TWOsQPnnofew70YtqoQY7PLQ193e4D+KiZHeOJ1UYeGauQsJUiIEiwPr5qJy5dYMTyfetv7/m282PNzg4sWbUTNy6aASJCY/M+O5LT68nfTxhFQa4D6ja5bG49mFR42aKjK5H/RDatXHTX6759+WU3/MULG3Ht/Y2okO7klebrzz7QiInDB4Y9nbR44I2tWLW9A189ZzpOnWZEwvslGMsVrKEzWeNjv1qKvzQmC3Q5FBsAbv7HGizd1IZt+7pxq5RHxSKMDdqNlcdj5KCqpG2Af8qA7z25zn59xBBj37+t2JFyYfK3r23BN/76rkMInXFUcjqLGx5cgW/89V37vZUoq8bMefIZ82Y2WMqB8vW/rk46znGThmFs7QD8/LK5OGr04KTPZS799Rv4zcub0WWmOxhUFUNnj5GcrNL17F9TqeLxG05B3aAqfPO8GTh75iicf+wYR5sLfPK3AMCjZri+Nb+6LmyzzujaAQCA3rj/Hfr93Ubem4GVKmqkVA3WPmPNY8jEfEw5q8zEZv3S09ikETX26w/2dQUmacuEqSONm/uqbfvx7JqEkmApIEUTWMQw6XD96VM8t4f5Wcd13SHgnJ/5eRIYAsDShAFg1JCEcA+TE/zkKQkt0ktj9cwkKLU7YsgAVFeoKSrXGJ9NGF4NALj5gplovv18vHvrufifC2b67vfX/zgJS2/6MC6aOw6qQvjEceMxxkPYAcmLqpoQWGAm5ZLNF3/9jxOx5rZFmDl2CBq/fRauO20K7r2yARdIAv2OT87B/14+z3dcDfXDcfnxE+35lc07Q81UCGEiZ++7egGICN+9aJbj899etSBpH7f3TJD2W+tKr3B8hsnJ/Pj8mVPt1/JTpOWJky8XVRboTE7wWwQK82Cv6QmPETf+4dVWv4kLR5YjYbxX5Ed1L9OOl1xyCyvDfOHfh19ZNb/j+xFkJhHmLFt9+Xl3+GmN8vYwmqWqSH2JxDpGwobuv687v0pSVKjHPNneM+b5B01bhZr6eFnB57cWZhE8m7BAZ3JCJotvmq4nXYgWqTR0vwsnzMKsnGkxrE3ZfVxD0KZe1M30Ag9j95ZLuXn155efJSbNfRgBGFMU2288riX6Sni5pJ4Pv1wzXv27C0oEPQG43QXzoSl7FUzJ16IoC3QmJ/j53Yb5WRvuZT4aeoqsifKFI99Twrj/pRLoXlq7W/P3c19zt/fSfKPcA4P6sUp82NkHfQJq/Fyj5bGFufEoRLaZRxOJRFQJge6/r+2n7SoWYeElgOVFUV0XgU82bsUiZ3748m/NQ6BzYBFT0sQy8Hd2h/DL+KcoNfuNuJ9MlSTQvZRKL7ON+7ipTC4Jr4fMLr1QGrrlSugT8u6roUvbw5hcYio5bh7Wd291GRwo5tLQXb8b73Enblip3Drdfvf50NAdNnTX+eUaFuhMTshkVd+rNqj8mfd2PbDfMAK9Uk14WXh5xXj1nWRyoWCTS+IRPOVwAlEDQs3dfWk+GrrfOoc8tjCCSA57lxdFiSilCcot8Nzfn/eThSTQU8xBkoZeIJMLC3SmpMkkMs4dwm+hULRFUZkwAt2q7AP4mFdCbEupoWepyEIUG7ocji/jd/PzS0HsP5bEecmLotaxosxHUmZFjzHKAUupTGnuG2c+bNlei6Is0JmSJpPcFe4QfouY4h+an+rCCRNxKffppVQGRQJaqAqFK3CRBYGeSpjZwT4+TzzZWhRVFSPCVph1O2UzSdT5CLMoKmdbjKqh58PbxJG6gTV0phzwM6GH8R3xy4qnKEE2dEN6ZaKhO7L9hTS5eAn0sAUuUhEU3JSqHyBxDn4CPcyiaJhxWm10YZp3XBp+UIEL93yEWRSVsy2m+l6TjpeHxUl5TLkqquEHC3QmJ/gJ1r6AqEHA0Gh2dXR7mmzcdmMhFS2wHuv9Lhz3fi0HetDvsgXI+3a5ikrrPvbalgM9jvdEwP6uPvTGNXT1JaIS45ruOEYYjS1IWClEECJY6Gu6QEdXPw71aYGCMWh7WJMLALQd7EW/5kphTIYZ5lBvPGmsPf2aPc/pmFx647odARuWfJhcvBZFOZcLU1Ks2rbf8X7s0GrPdn9ctjVpW9vBXowwQ/b/Z8karNl5IKnN0IEVSUL1o3e/jlXbO9B8+/megnL2uKFoOWCEYcuP/X9cthU3/2MNBrmiUWWPiE//7k28+c2z7Pcf+ulLjlQCFi+ub3W8j2sCr27ciw/95CXs7EgI+6nfehoA8O3zj04ap8WIQc4izLtdNwsZ62a0+0APxtR6z/XZd7ziGJfFpBEDsbWtCwNiqtduqJK2h1oUNdsc/4MXAACzx9Xan8VUBZ09ccz6n2fwudOPxE2Lj7Y/+/BPX8aO/d1GnxXGXcEtvys9AswUxagQdNeLTbjrxabAsbkD1Nw34GxRVyNHJSfm+v3dnTnpzw/W0Jms4L5QTp02Eg9+diH+7YSJPnskaO9KJNF654N2+/XfP38y7v/M8Xj6i6fi+S+fnrQQaOXuALxt0z+/bC5+/PFjMWF4tUOg7TYF7UEzr8eFc8biketPdGiD3S4N3UuYW9x64Sy8+NUzAACLZ48GAIcwl3EH0sgsPma04yaz30xc9V9SWLlFvZmjpP1Qf9JnXpw6LZHW4P5rjsfvr16AYTWVnm0n1yXyn6SjWco3T4UIHd3G93vfa1sc7SxhDgBHDDbSGEwdmchT88Bnjkd1pfdNx625HzG4KqnNY/95EgZVxXDPp4+zt1X5RCBnyuzxtXjouhMwZ8JQzyerqUcM8tgr+7BAZ7KCl7fHSVPrcMXxkwA486pYVNglypKPV12hYu6EoTh9+kgcPWYI6gZVBQbTeOWdrqmK4dKGCRhbW+18DHYd41vnH40F9cNDuRIeNSo5MdZ5s8fYQnDW2Nqkzx3jDAgsqlAVfObk+qS2cyYMTWo7dKCRoyRsvvQ6Sfuvr6vBh2Yc4dvWWcYvukB32tCBvhRFogcPSNzEZI38tOnJyc7sPlxjnDV2SFKb+ROHAQDmThxqbxs52Dv/TTY44cgRGOBKwWyZBHN1I3HDAp3JCm6hbF1vQQFGUQsgqAoFuC1aAt3DO0Z17ucV3Qm4vFx8hhQUiu5+HTROv3bW+HUpaMazzwzqdaZCbppplsCYoqAvrqVoE81m797H2M9flGUaxBUFt1dPIpcLC3SmhHB7hZCP14JM1AIIKvl7dgR5Eyiu/byCgdz7+qXbDQpFt/oKIsjkYmxPtAtaQM2kXmcqiKILWD8UJfVCeNRFWMArYCh821zi9j6K24ui+emfBTqTFfwe/a0L1OtjO+JP+tB6KTwcHJUQGrpfAQd5fO5jWOOQ9/ULbvSOuAwvkHRhFFF2V+FxH1+XfKw9PT2kdm685i7dQK8wJhf3EOT+VSK7+pCfdSiqmyTg/B4Egufd+ZsIdwNMF/dTpDtXTa5hgc5kBT9f4yCBECYbn/tYqTR074Akpy+0+xjWGOV9/TT0oNwifp+7xxnUxpGnJEBDt7YF+Xg726d3qWfqbqcqlFJDd5hcQuYAKlqTi8/TIJtcmJLCT0O3BIKXgpIQXoltVjvyyMuohFgU9bpujGyAktbksYDr3lf38fFOFUKfSgDqrsAbv2OlMrkkgnmSx+g1d+lqiGH2czeR+1cVsisIye3kuXWnCgiDI6sm/APZjLbO0eUSxeWJFfTkmJP+89MNU+745esIkm/pVIVPZXLx1NBV50XmFd3pta9XV5kuirpD4/2On/VF0TSzX2aeokDx1NDlcadjQy9WDT3Gi6JMOeBnNvHSFi0iV4XPYFHUKxzbPQ63LPEyu2RjUTRIi3fkKQkoX6ZEnLu0NfSMBbp3TVH5O3CnCghDcoqAoLahDpkVFJdZMFvZNUP3n59umHInnarxQYuiXoRxW/Stah9iUdS9UOl1j0plUgmzKBrURn5qCSowHPXpJl2BkrFAJ0pKsQAEmOhCdpeUIiBgR78F6FygkvM3mu8CFxz6z2SFkGtzDmKSeQEAnli9E2t3JYf9W6gKYZ35edvBXnv7ig/a8WrTXvOYyZJLVQhb27rsyj1vbG5LGoMXtz2xBuOGVmOaFEzU0x/sU51KAL64fk+gFde68Hv6NTzwRrMxRg9zidXPH5Y2463mffjsqZPtaMtujzGm+8ifqUDf19WHjm4jmrVfE/jda1sghMB0jwAtILzwlW8Iqbxc8knMpTy8sM5IPZGv8bFAZ7KCJtX0nCtFNloRjTecOQ3f+ft7jn0uO34ibn/6fcR1I8nWDQ+usD/7yjnTk/rY29lrRx3e/8ZWe/vHfrXUtnd7yS1LS1rf0omjxwxBy4HEzcBL466pVHGoT8Of39qW9NlbW/bh2lMm43euMHaLMbXBkYjb9nUHfm6N56X1rXi9ybjxeGl3VuTna0178Zp5M/vmeUcntQOM76CmyjuEPhXufDdeLJw8wuGB9KGjEhGe7vP97hNrAQCVmSTMB7C9PXFcTReYMtIZWj9x+EDP/S6eNy6jflOhKGSbyoBEeop8PSWwQGeygvVUvfqWc1BdkRAeAypUNN9+PgDg0ydMQv2NTwIA/nLdCRg0IIbbn04uJdYwaRg+e+qRSX2cMq0Or2wwhNdBKcuebHXwEn4XHDsW/1i50370Vyixj7t98+3n4w+vb8Etj6/1PdfvfGQmFk4ejuv++DbOdIXQu5OSXX/6FPz65U2ObSdNGeF7bOuJobMnkaPF66ZT50rkdaA70b66QsUVCyfaN513vn122u6HAypS3wiOmzQMG7+/GJNvegoA8OVzjkq5T19A1Qvr9xJEw6RhaNzaDgA4d9YoXHPyZFx5Yj0UMsx27vMNc8xsoJJTQ1fI+A3kCxboTFbQpdX8MNpITCXbDCAH0QBBUZT+BS6C9lUljxAhhOMG4GVyUUNoj5ZdOx0xGQs4vu1fLg3Sa4xB8lkXwmGmyUfq1nzaqY3+pNfmt2DNXZ6H4kBVExWarN9a0PedbXhRlMkK8QCPDC8UIs8w96BjqAEFLiy8BIuzZJlrHAE+3tnA61CBPtOWf7mPF0jiuOQr1P1KzjG5R64p6/cUmEtYoDNZIeGREa69QuQQXrLm7SvQQxRG9tzPI/oyqK9sKlReDxRBNz072CrEfPhpxVoKTxomd8gpnhOBYfnrnwU6kxV0s8xZlEdvy+Si6cKhkQaZXPzcFoOQfbst05A1TG+BntvLIjjvSDiTix+6LiBE8Xh9HG4YeYOM17odGMYmF6bEiKfxmG/9zjVdOASY33FUJXx2Qed+CQ3d2t/ysvBOfBW5C188TS5BfuheJpcIwtmOLmWTS0Ewsi0aJpc4a+hMqaILETl4xaE5hxBgQblcgpCjKjW3QA+IwswGnlkmg1IKq8kaehThnO8alowThcgOSAsqZpKz/vPWE1PWGDlKov2cvKIiAX8BFpTLJQg7gEm6cXjVqky0z+1lEZjLxTx3OboySh6WhLcRC/RCIAcWpSpmkgtC/XKJaBERrSeiJiK6MaDdx4hIEFFD9obIlAKaLiLnzJC9T+Q0sH4KTVCBi8B+pFSz8RACPdcmlzC5XPrj6WnoqQpoMLnFyrYohCjId5Hyp0tEKoC7ASwGMBPA5UQ006PdYABfBPBmtgfJFD+aHs2zQg7XNtwJU+dzsYs/uNqnwvamkRZFKwKkdphHZOH679vOy8slyORinqMceOM3r8JjzvQCPOZnilea4tT7SK9zXLQiCom0xomnpXyav8LoIscDaBJCbBZC9AF4CMBFHu2+C+BHALzLnTNlzZtb2lI3klCJbEF12xNrcfpPXrI/G1LtHe9mPbq6/dZTYQXZXP9/7+BQrxFhahWolivP22MLcQFa+/tVpbfwKg4cJh/6OimnjV97eQqWb90HQCqokGa63HxinVY64rhGSklQHSKaNV9YesL63Z1ScYv8fRdhIkXHAZCTWmwHsFBuQETzAUwQQjxJRF/zOxARXQfgOgCYOHFi9NEyRUttdYUjv4YfP7t0Dn732hYcMy65SrvFF86c5rndUZ7NQ6ubMdo74ZMsEN/f3QkAmDW2FptaD3m2HzUkOR/LgAoFMUXBnz5r/PRPmzYS//XhabjmpPqktvde2YCfPrse8ycNw/WnT8HRYwZDIcJ1f3wbQHAk44ThRuoAy4b+bydMDDQPWQwbWAnAqaE//LkTsasj9XfixR+uWWAXpgjLbz59XJJw/dt/noSLf7nUfj9heLWd3+XiuePw2Iod6E9R0ciL//eJOfi/ZVuhC4FrT5kcef9cYSVya2o9iHlmTqN8Pi1lHPpPRAqAnwG4OlVbIcQ9AO4BgIaGhuJ5TmIyRtMFjps0LGW7S+aPxyXzx9vviZLNEhN8EivJ5dl0XWDUkCroAmjtNJJtXXlifeB+1r4AcNTowcAq7zEOr6m0Xw8eEENnTxwPfGYhjp883N6uKIQvn52cQAwAzp45CmfPHGW/X3TMGADA1SfV4w9Lm42+fbCSYVkmly+fnTovymnTR9q5XDRpUVQeb1TOOOqI1I1cnDtrdNK2eROdv4mbFh+N//zTO0YfM47AYyt24Ogx/jd3P0YOrsJ/+8x/IbGySOrSU2Q+n5bCmFx2AJggvR9vbrMYDOAYAC8RUTOAEwAs4YXRwwstRWk1P6Is+Mnl2bz83v3M4qqHQA/K9pfr6NEgbBu6qbWGmR+VEudlLS4Xq9uiPO/l6Cuvun6jQPG5LS4HMI2IJhNRJYDLACyxPhRCdAgh6oQQ9UKIegDLAFwohGjMyYiZoiTdcPMogkcuz2blNnccy+fCUTwEekWA1uR1nHxdlFY//bZgTr2PHG6uF3lgkayt5jPgJl9Y35e8cF9UXi5CiDiAGwA8A2AdgIeFEGuI6DYiujDXA2RKA01P74cbZcFIznOiieTanH6Ptg6Ti7DcFv0X0rzGlK+akDGXhh6mXyPc3Jk/pFgXReXzKSVPnLDY6SykDKLFtigKIcRTAJ5ybbvZp+0ZmQ+LKTU0XU9LK4xkcnGF8IfW0ClZQw9aaPR6ashXOg63ySWshm493hciOjEK8vkU6xgzwTo/2ROr2EwuDJOSqH7oFpFMLnIaXE8bul8OmGgmF28ben4uSiICUWJRNMwNT5HqWGoFeMyPQrGagrKFnIsnkW2RBTpTYuhpZviL8jjqToPr7s/vWF4C3cs/POg4eX1slvoKM6dyuHkhhEgUitUUlC3kDKKFuLmyQGeyQlzX87Yo6ifQ/R5t5XaWf3egyaWAi6JyXwqFqwSkKGR7t+S7ynxUytHMIiNnEGUNnSlZdD29izWK4JGzM3p51QQVxrCwTBlBof+FNLnIfYXtU6XkRdFi1dCLdVzZwvEbLcDNlQU6kxX2HuxNyywRZRfrYtnceshTQw9jQ1+70wipD87lEnyMXGMtcIaN1IyphLaDfQBQEFe5KJS7hm7N+8GeuL2uwRo6U1L09Gvojes4aOZJicLpR40M3XbwgAoAwL8/0IhdHT1QiXDG9JHS58E5YADgidW7HNtOn57cv2XmOHVaHc6ZaUQ/1lRmXk/diiIcN7Q6sF1fxFD4g70a+jQd3X1a5Nqu+UAeyqCqmD334800B8fVD/ParSSxbOird3QUJNti5r9S5rCnp18D4J9LJYjbLjoGF8wZi9644fY4a6x/GPgpU+vs13sO9GB4TSW+f/FsfKJhAlQFmD/RWzAoCuGHl8zGTY+969i29MYzHWH+MtZnuhD47KmTMcynXRQubRiP2eNqA88xCitvPhu6AP781gd4fBXQ3a9JtV2LR6Cv+M456OqPY9+hPtTX1eDFr54BIYCJIwbixa+egUk+qR5KEVUhDK6Koba6IvFdsEBnSgnLVlg7sCLyvhWqgpOm1KVuCKemowtDy66MKaFylljasUVMIYwN0JTlz9LJNeJFTFUwe3xtVo4FAEPNhFxDqo15N9w5rb6KR6DXDqxALSowptaYUzlXz+S6mkINK2eMqh1gRzMDRVjggmGCKEQARVSvmrAeMaWIo1CIKdHL6fxKDaMQi160uVwYJpBC+NtGTQYWNgipFLHWdzVRmPwhjBOjahF4UZQpTQqxEGfUME1fQy+nmpuqFcyiJUr5ldP5lRoxhaBJGjqbXJiSohAZ/nSRXlCSRbGml00HLw2dTS6FQ1EIWhGXoGOYQAqV4Y81dANVDjcvwkXRw42YQs4CFyzQmVKiUBn+MtLQy0iD5UXR4oIXRZmSplAZ/iKlDTgcFkULVFSBcaIoRioMXhRlSpJC5Q+JZHJRy9/kogvJ5FJG51dqxBTFzjdkvGeBzpQQb2xqA5D/DH/p5FJPZ99ix9LQd3f04K0txndRTudXavTGNby9tR072rsB8KIoU2K8vbUdADDliEE57+ukKSPs11Euk2E1FZhg5g6ZPa4WQwZEj2rNF9efPgUAcPbMUaHaWzlu9h3qQ2tnLwBgRBZSFTDpsbzZuB5++dImAPlVdDj0n8kYXQjMGD04L2HcXzprOpZuegMAEOU6qYqpePXrZ+ZoVNnlxsUzcOPiGaHbW8m+BAR0AcyZMBQDKvxrpjK5ZfSQAdh9oMd+7zb35RLW0JmMSbf8XDqUY6X4TLHm3qpjyR6LhSUprTN7uTClRD4FOrvjJWPNieX7zB4uhcVd2Ju9XJiSQhP5E7Qx99XC2F4UVh1LFuiFxf0bZYHOlBSarufNNYvleTKK2+TCAr2guKefTS5MSaHpIm+uWbKwEuEqtJU91pzoZh1LNksVlkLmDWKBzmSMsRCXL5MLCys3MZeGznNUWOQbar6/CxboTMYUalGUFVEDXhQtLuTfaL4DvFigMxmjifwt/MgLTmxyMUgsihpmFxboxUPeo6fz2htTlmgRy8FlAi+KJqPYAt3I8McCvXhgk0sJ88/3dqH+xifxm5c3JX323o4OzPjO0/jKw6sKMLLccag3jvd2HMhbf5VSZNHgIg7fLwS/+FcTmvYcLPQwDntG1w6wX1spdPMFC/Qssn63cTGt3ZUs4JrbDqGnX8eT7+7M97Byyr5DfQCAiVIl91wycnCV/frfT5uclz5Ljb4426IKyR2XzrVfLzpmdF77ZoGeRTSzuIDXTdlKMUuRUkoVP5YGMmdCbV76I8kmOaa2Oi99lgKDqzgtU7FQO7DCNrVcMGdMXvtmgZ5FrPzHuodE1/L86JUvClWtiHHC6XKLk7xX8cprb2WOVVzAS3iXq0DX7ST+/FMqJOx7Xpzk+7rgqzCLWCYXr4WQchXocc2qVlTggRzmsIZenORbz+HLMItYGrru4SCtlanTtHWubHIpLCzPixP2Qy9hLOHmpY172dXLAetcY5yEm2GSyPd1wQI9i8RNk4uXQM+3P2q+iPOiKMP4UpSLokS0iIjWE1ETEd3o8fmXiWgtEa0moheIaFL2h1r8HM6LohydyDDJ5Pu6SCnQiUgFcDeAxQBmAriciGa6mq0A0CCEOBbAowB+nO2BlgKWWcXLXu5lVy8HrBsVC3SGSaboBDqA4wE0CSE2CyH6ADwE4CK5gRDiRSFEl/l2GYDx2R1m8dPTr+H5dS0AgLe27MPO/d2Oz1sOGNXYu/u1pM9KgdXb96Nf09G0pxMvrGuxBbkt0NnkwjBJFKNAHwdgm/R+u7nNj2sBPO31ARFdR0SNRNTY2toafpQlwFPv7kKbGQYPAJ9/8B3H59vbu+zX331ibd7GlQ2a9nTiwrtexw+feh+f+PUbuPb+RjQ27wNQOA3dqnTPGHxsfkKHmpunqF3Gn/OPNSJEhw2szGu/WY0XJqJ/A9AA4HSvz4UQ9wC4BwAaGhrKygZxqE9zvN/kSpJUFVNRN6gKuhDocrUtdlo7jRvVezs60N7VDwDo6jfOoRACff33FvEirIuvnnMULlswEQAwYTjf7ArNTz8xB986/2gcMXhA6sZZJIxA3wFggvR+vLnNARGdBeBbAE4XQvRmZ3ilg2U/H1FTibZDfY6cI4BhVx9SHUNtdUXJ2dPtU5FOSXebXPIo0Ktiat76KhUUhTBxRH4SpDGpialK3oU5EM7kshzANCKaTESVAC4DsERuQETzAPwGwIVCiD3ZH2bxk0qw6WZpsJhCZeHxorkWgHlRlGEKT0qBLoSIA7gBwDMA1gF4WAixhohuI6ILzWY/ATAIwCNEtJKIlvgcrmxJJdDjZvFehagsfNKTFkVZoDNMwQllQxdCPAXgKde2m6XXZ2V5XCWH5gqBFy6zim5WklEVQl9cz/v4MsHLQqQJ9nJhmGKDI0WzhDsE3i0ENWGYXFSFyiKvi3W+HFjEMMUDC/Qs4dZU3WYVTRdQLIFeYiYXL+XbOodEtkUW6AxTaFigZwm70INVsFckC3SVCCqVnkD3NLm4FkXZjZBhCg8L9CyhCwGFEp597uyKmmRDLzWB7oXuqs7E2RYZpvCwQM8ScVNgy+9lSlmguxd4gcT5xXlRlGGKBq4s68Hza1vwwLKtWL19P4ZWV+CHlxyL37yyCS0HelE/YiB+eMlsDHWF9K78YH9Scej6G59E3aBK7D1oRFqeOq0OikLYuOcg1uzswKyxtfjeE2uxY383vn/xbAyvMY55qDeOb/x1NT65YAJOnTbSd5x3PLcBlTEFn//Q1OxOgMRPnnkfr2zYC8DIUWPx4Jsf4FMLJyUKXLANnWEKDmvoHixZtRPLNrdhf1c/mtu6cN/rW/DS+las23UAT7+3G+/tOJC0T3WlCk0XuOuK+Y7tljAHgMXHjMHp0w0B/fKGVggh8NvXtuDp93bj3R0ddrsNLZ14YvUu3Pp4cM6Xn7+wET95Zn0mp5qS+15rxu4DPUnb9x40goFt7x4W6AxTcFige6DpAhOGJfJh9GtOv3Evt8O4LjBnwlAcNXowvnL2dM/jXrFwIj4618hrpuvCYXqRbe7W9kO98fRPIktousDHj3Mmz5wzYai9UOpeDGYYpnCwQPdAc9nD3QLdq5ycrgtY64JBws06rqY7bwyah0AvBjQhkuzjlSolldtjGzrDFB4W6B5oQjjc8NyRnX4ViWJmie8g84P1kSYEdOmwfsK9kAghbP95mcqYYi+Gci4XhikeWKB7oOvC4YbnFuheuVgMwWe8DhJuRJani27XILX2t18XSSSpNaRkDV1J+KFzYBHDFA0s0D2I604zQ69LoHulv9VEwkyTKsjGCC6CU0P3MLkEyXUvV8Js405nYFGhKknl9tjkwjCFhwW6B7pw2tD7tNQauuGHbppcUgTZeGnoekSTSz6sMvaCp1tDl00uugARL4oyTDHAAt2DjBdFU2noCiUtilo5Uaz+Ae8cKu42uSRhH3dur4wpjkVR1s4Zpjhgge6BlbvcIuyiqKWhhxHoeoaLovmoepTIde78mVS5FkXZfs4wxQELdA9SLYr6C3TjdSqFVVUIcbfJJeKiqGz28XpiyAYJl0Tn9kpVgRCmF4zGAp1hioWyEOiaLtDa2YsDPf32NiEE9h7sRWun8ec2mwTR2RN3aNlWYWSL3nhykef93X2hBRsB6I87NfSO7n70xjV092nYb/Z3oLsfQggc6o0jrulo7exFXNPRfqgPXX2JoKO2Q32O4/f0a/ZcZBKcZJ2n+7wqzDtXZ28cnT2FD35iGMagLHK5fO2RVXhsxQ4oBCy54RQcM64W9766GT946n27zanT6vDHaxei/sYncfG8cbjjk3M9j9W0pxPrWzoxYlCl5+cA8ONn1uPTJ9bb7/++YgdaDvTagq66IriIsSYEXt+0FzPGDLa3/fDp9/HQ8m3o6O7HPlNAH+rTcO6dr2BDy0EcO74Wq7d3eB5vwfefx71XNuDsmaMAACf88AXs7+rHf314Gn7xwkbcdcU8fOTYsYFjWtq0F1f89k088QVj/gDgmt8vBwBUuc5n8IAKAMCxtzxrfB4rC72AYUqeshDo2/d3o1JV0KfpaDnQg2PG1WJHezeqK1R88/yj8fDybdixv9tu/7cVO3wFessBI0fJhXPG4qbFR+OCu14DAFzaMB7zJw7DjY+9i8FVzmmzjv2FM40kWefOGo1bL5wFTReorlQxqCqG+ZOG2e0HVcUwcnAVevoNFf3HHz8W/1i5A683tZn7j0JNVQyPvbMDG1oOAoCnMB9cFcNnTpmMn7+wEbs6EudnafivbmwFAKzf3YmPHBs8h8+vM2p7L9vcZgv0ju5+VMUUnDd7DGaOGYK3tuxDfd1AzJ84DB/s68Jf39kOALjqpPrggzMMkxfKQqDrpuDs69YdhRcGVqr49AmT0Ni8D6u27Q91LGv/qUcMwuzxtRhTOwC7Onpw6rSRuGDOWLy9tR2vNe1N6h8AJo2oAWAk6goSclNGDsL+rj57YfOiuWOxqfWgLdAX1A/HomNG47F3dgSO9bOnHomrTpqEn7+wMVESLou2dSGMsQ2qiuGYcbW2oAeAhZOH2wL9hCOHZ9QPwzDZoSyelTUhUGk+9ifc6RK+0SqFr+PpF8puhfPH1OR85lGDa2JmXdFEpkLFsa+qkJ1GIPA4KiUqJLkCfdyv08HwYPEeh+x37teGYZj8UhZXoqYLVJr260TAi24LSUUhO0Q95bF8QtkVKQo0SaBHDK5RFEJcE/ZYFXL2F1MIYWSkYpa0s8Yg/wecvu3pIHvuuJHz1bAfOsMUB+Uj0E0NPSHYEkLS0ohDHcunRqYltFSPY0UNrlHJ8kM3y9aZ+V0sFIVCHU9VpOyNIlmgW08rYU5dwMcV02ccimO8qY/PMEzuKYtLUdbQbVuynFvFLPsWxqbsVyNTVSWBriWbXKL4Yqum2SYuZWh0mFwonMlFVRS7X2vcsn96ptGkuu5vcpHHG2asDMPknrK4EnUhUBFzmh7kGp+qaSaJErDj1kxtDd3DHh81uMYajy4SGRqdNulwJheVEuOyxu1VKCPMwwMhuVE8wOSiOsab+vgMw+SesrgU45KGLlejtwW6qaFHCam3BKwlu93HkvEqAhGEZbaRTRoxl0APc4MwBD+BCEnZDwGgX8vQ5CKSc6HLfVukSnXAMEx+KAuBrks29EQ1et1p9w4p0K2FRHeRikCBrgvbJBMGy2yjuW468ufhBHrCXCNnP7SwskSm6+2i68K3WIe8nU0uDFMclMWVaLgtGtGMtqYquy1aGnEIweZeFLWUT9V1LMc+aSyK2hq6Rw51NcKiKGCuEXgsilo5aNL1R3fnhZfhRVGGKT5KPrDosXe2Y39XPypNDfnlDXtx4pQR2NDSiSHVxumpCqEvruN3r26x9/v1y5sQUwgfnTcOdYOq7O3LNhnBPUmLopJAFwL41Uub8KEZIzFj9BBs3HMwlJ3aQlEILQd68e6ODs8c6ipF09AhgAeWbsXwgZXY353IO2Ple3nng3b8+uVNqB9Rg0XHjLY/F0LgL8u3YX93P5aaQU0vrt+DuC4woqbSHqtn37woyjBFR0kL9D2dPfjyw6sAALPG1mLltg48v64FNVUqeuMa9hwwkkvVjxgIXQA/f2Gjve/tTxt5XnQhcN1pU+ztb2w2BFtttZGv5NKGCfj5CxsxasgA81hGNOiP/vk+Vm5rx28+3YDefg17DzoTZAWxoaUTALBy2340mCkBrP4AYNywahAR6kcMRHNbl7194vCB+GBf4v34YdUAgMl1NVjf0okfPp3IXQMkbOjLm9uxvLkdqkJo+v5ikCmMN7UexI2PvevY5/WmNjtiFfCvjzpm6AD7dV1A3huGYfJHSQv0XjMXyg8uno0rFk7EF86cinPvfAV9cR0KEU6aWgcA+OSCibho7jgIYZhQhAD6dR3H3vJsUmpchQgXzR2LgZXG1Pz32dNxw5lT7cRbH503DouOGY2P/3qpvS8R4RSzrzDMGT8Ub29txzcWzcDnTjsSAHDSlMT+x44fCgB44StnoC+u29GpAypU9PRrqFQV9Os6qkwz0+NfOAXTv/00AOCHl8zGJfPHQSVCv2akAY5rAr96qQm/+FeTUczafBqwcsn87+XzcNbRo+y5+fvKHbjJFPR+GvqUkYPs1yOkJxyGYQpHSQt0yyNlQIVltlBQYRYw1oVAhWTGGODKGFilW37rycd0Zw+scPnlDahQEVMUWO7o7r7CUiGF7ntpwqpCqK5UzbbO86hSEucj911dodqC3vyHCjWRMVETwv7SrfmrrlDtfow+Eufrp6EzDFN8lLTx0/YZd3mIWB4tQaH4iRwoyfVCw7oMWvvGs1DkIZOanETyAmWwm6FXMWq3h468QMsuiQxTOpS0QNf9BLrLx9sPr5QAuqv8nB+y+6Iuwu2T6njZwE+jdud8kV+750le5ORqRAxTOpS0QPeK6rSSZ4XRtBWFHKHy1jHDmBmsaE97nzRMLjLZMm343Vgszd1Rx9Tjhmi8z/64GIbJPSUt0C2BJJsZYkoi8VUqga4SJflo6ylMNfa+soYeUqsPIlumDb9ztgSzV3rdpMySIUw4DMMUHyUt0K1FPVmLtFLThkmYFVMoaVE0bBi/YdqR9slQ8OXa5GIJZrkwtZ+G7vaJZximNChpgR4P0NC1kCYXz0XREOaTrC+KZklu+mnUsQgmF3fUKsMwpUEogU5Ei4hoPRE1EdGNHp9XEdFfzM/fJKL6rI/UA93Dhi57uaTSLr3C+PWQYfyGrd7cJ2JyLi8oWyYXn+PYi6LS+VpPOEmZJRUW6AxTiqQU6ESkArgbwGIAMwFcTkQzXc2uBdAuhJgK4A4AP8r2QL3wcltUzERVukht//WqPhTebTHh8hh2n3zgF4Vvu2lKudzjPtWZ3DdIhmFKgzCBRccDaBJCbAYAInoIwEUA1kptLgJwi/n6UQB3EREJkWFRSw8eXr4N9766GQDQ1WeE9ssmgphCeH+3EVofxm3xidW70Njc7tgeZoEypiho3tuFs3/2MvYd6ou0eGhlhnQHLGUDv3O2TC5X3vem3e/BXiPXS1J1Jk6NyzAlSRiBPg7ANun9dgAL/doIIeJE1AFgBIC9ciMiug7AdQAwceLEtAY8dGAFpo1KhJ2fNGUEZo9PVKO//PiJqKpQoBDh3GNGBR7r+tOPxFvN+xzbjho92JHAyo9LF0ywc4hPHzUYF88bF/ocvnDmVAghcNnxExzbb71wFo4zc7tE5dYLZ2HNzg7MGlfr+fkJR47AxfPGoTeuObafUV2JKUfUOLbNGleLSxvGI64JLDxyuG+fd18xHzVVqu/nDMPkF0qlRBPRxwEsEkJ81nz/aQALhRA3SG3eM9tsN99vMtvs9TomADQ0NIjGxsYsnALDMMzhAxG9LYRo8PoszDP/DgCyKjne3ObZhohiAGoBtIFhGIbJG2EE+nIA04hoMhFVArgMwBJXmyUArjJffxzAv3JhP2cYhmH8SWlDN23iNwB4BoAK4D4hxBoiug1AoxBiCYDfAfgjETUB2AdD6DMMwzB5JFT6XCHEUwCecm27WXrdA+AT2R0awzAME4WSjhRlGIZhErBAZxiGKRNYoDMMw5QJLNAZhmHKhJSBRTnrmKgVwNY0d6+DKwq1SOBxRaNYxwUU79h4XNEox3FNEkKM9PqgYAI9E4io0S9SqpDwuKJRrOMCindsPK5oHG7jYpMLwzBMmcACnWEYpkwoVYF+T6EH4AOPKxrFOi6geMfG44rGYTWukrShMwzDMMmUqobOMAzDuGCBzjAMUyaUnEBPVbA6x31PIKIXiWgtEa0hoi+a228hoh1EtNL8O0/a5yZzrOuJ6Nwcjq2ZiN41+280tw0noueIaKP5f5i5nYjoF+a4VhPR/ByN6ShpTlYS0QEi+lIh5ouI7iOiPWYxFmtb5PkhoqvM9huJ6CqvvrIwrp8Q0ftm338joqHm9noi6pbm7dfSPseZ33+TOfaMagf6jCvy95bt69VnXH+RxtRMRCvN7fmcLz/ZkN/fmBCiZP5gpO/dBOBIAJUAVgGYmcf+xwCYb74eDGADjMLZtwD4qkf7meYYqwBMNseu5mhszQDqXNt+DOBG8/WNAH5kvj4PwNMACMAJAN7M03e3G8CkQswXgNMAzAfwXrrzA2A4gM3m/2Hm62E5GNc5AGLm6x9J46qX27mO85Y5VjLHvjgH44r0veXievUal+vznwK4uQDz5Scb8vobKzUN3S5YLYToA2AVrM4LQohdQoh3zNedANbBqKfqx0UAHhJC9AohtgBognEO+eIiAPebr+8H8FFp+wPCYBmAoUQ0Jsdj+TCATUKIoOjgnM2XEOIVGLn63f1FmZ9zATwnhNgnhGgH8ByARdkelxDiWSFE3Hy7DEaVMF/MsQ0RQiwThlR4QDqXrI0rAL/vLevXa9C4TC37UgB/DjpGjubLTzbk9TdWagLdq2B1+OrMWYSI6gHMA/CmuekG89HpPuuxCvkdrwDwLBG9TUYxbgAYJYTYZb7eDcCqml2IebwMzgut0PMFRJ+fQszbZ2BochaTiWgFEb1MRKea28aZY8nHuKJ8b/mer1MBtAghNkrb8j5fLtmQ199YqQn0ooCIBgH4K4AvCSEOAPgVgCkA5gLYBeOxL9+cIoSYD2AxgM8T0Wnyh6YmUhAfVTJKF14I4BFzUzHMl4NCzo8fRPQtAHEAfzI37QIwUQgxD8CXATxIREPyOKSi+95cXA6n0pD3+fKQDTb5+I2VmkAPU7A6pxBRBYwv7E9CiMcAQAjRIoTQhBA6gHuRMBPkbbxCiB3m/z0A/maOocUypZj/9+R7XCaLAbwjhGgxx1jw+TKJOj95Gx8RXQ3gIwA+ZQoCmCaNNvP12zDs09PNMchmmZyMK43vLZ/zFQNwCYC/SOPN63x5yQbk+TdWagI9TMHqnGHa6H4HYJ0Q4mfSdtn+fDEAawV+CYDLiKiKiCYDmAZjMSbb46ohosHWaxiLau/BWbz7KgD/kMZ1pbnSfgKADumxMBc4NKdCz5dE1Pl5BsA5RDTMNDecY27LKkS0CMDXAVwohOiSto8kItV8fSSM+dlsju0AEZ1g/kavlM4lm+OK+r3l83o9C8D7QgjblJLP+fKTDcj3byyTld1C/MFYHd4A4277rTz3fQqMR6bVAFaaf+cB+COAd83tSwCMkfb5ljnW9chwJT1gXEfC8CBYBWCNNS8ARgB4AcBGAM8DGG5uJwB3m+N6F0BDDuesBkAbgFppW97nC8YNZReAfhh2yWvTmR8YNu0m8++aHI2rCYYd1fqN/dps+zHz+10J4B0AF0jHaYAhYDcBuAtmFHiWxxX5e8v29eo1LnP7HwBc72qbz/nykw15/Y1x6D/DMEyZUGomF4ZhGMYHFugMwzBlAgt0hmGYMoEFOsMwTJnAAp1hGKZMYIHOMAxTJrBAZxiGKRP+P69oPM/grBa8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.signal import lfilter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(lfilter(np.ones(20)/20, [1], rList))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same happens with the alive time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jList)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that when the network started to get better at rewards, it also managed to keep the player alive longer. Unfortunately, the network is still not the best at this task. A human would take only eight steps to finish the game."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar strategy can now be used for the Atari games."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing breakout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Atari games can be played in several ways. The first is the interaction way. Either a memory view or the displayed image (which is always the same) can be used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with an empty, simple breakout game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the gym module\n",
    "import gym\n",
    "# Create a breakout environment\n",
    "env = gym.make('ALE/Breakout-v5')\n",
    "# env = gym.make('ALE/Breakout-v5', render_mode='human')\n",
    "# Reset it, returns the starting frame\n",
    "frame = env.reset()\n",
    "\n",
    "is_done = False\n",
    "while not is_done:\n",
    "    # Perform a random action, returns the new frame, reward and whether the game is over\n",
    "    frame, reward, is_done, _, _ = env.step(env.action_space.sample())\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing that now needs to be modified is how to get the new step for the game. Well, it needs more than that: first it is needed to train a model!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the context. Images can be obtained from the environment (they are 160 x 210 pixels), and considering the fact that lots of previous images will be required, this size may be too much to fit on one computer. One pixel can be dropped out of two in all directions, for instance, so this is what preprocess will achieve. Two functions that transpose the internal state will also be added. The reason is that there are images that are 84 x 105 with one channel, but past images need to be used to know in which direction the ball moves. To achieve this, this state is transposed on the fly to have an image that is 84 x 105 x state_length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import six\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import itertools\n",
    "from collections import deque , namedtuple\n",
    "\n",
    "Transition = namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "def to_grayscale(img):\n",
    "    return np.mean(img, axis=2).astype(np.uint8)\n",
    "\n",
    "def downsample(img):\n",
    "    return img[::2, ::2]\n",
    "\n",
    "def preprocess(img):\n",
    "    return to_grayscale(downsample(img))[None,:,:]\n",
    "\n",
    "def adapt_state(state):\n",
    "    return np.expand_dims(np.float32(np.transpose(state, (2, 1, 0)) / 255.0), axis=0)\n",
    "\n",
    "def adapt_batch_state(state):\n",
    "    return np.transpose(np.array(state), (0, 3, 2, 1)) / 255.0\n",
    "\n",
    "def get_initial_state(frame, state_length):\n",
    "    processed_frame = preprocess(frame)\n",
    "    state = [processed_frame for _ in range(state_length)]\n",
    "    return np.concatenate(state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although all the Atari games can be made work with the network that are being built, there is one issue. Every other pixel is just being taken in each direction. But what happens if space invaders are being played with a one-pixel-width missile? There is a 50/50 chance that we will die without seeing the missile!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this better, skimage.rescale could be used instead. For breakout, it isn't needed, so this is left as an exercise."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of hyperparameters is now going to be written, as well as some constants for the game, like the name of the environment and the size of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'ALE/Breakout-v5'\n",
    "width = 80 # Resized frame width\n",
    "height = 105 # Resized frame height"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is need to be trained for a very long time, so play 12000 games. To predict a new action, the past 4 images will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 12000 # Number of runs for the agent\n",
    "state_length = 4 # Number of most frames that is inputted to the network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters are also going to need to be set for the Q function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99 # Discount factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning, the goal is to test very often a random action (left or right for breakout). Then during the training, the randomness will be progressively removed (this is the epsilon-greedy strategy). Each time the network is run, this one step is considered, so reduce this random factor by over 1 million steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During all these steps, epsilon is progressively lowered\n",
    "exploration_steps = 1000000\n",
    "initial_epsilon = 1.0 # Initial value of epsilon in epsilon-greedy\n",
    "final_epsilon = 0.1 # Final value of epsilon in epsilon-greedy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of actions need to be filled in, so at the beginning it isn't trained, the game is just let play with random actions. This is going to be the initial training set, and over time all the games will be added to this set of training set. When it hits 400000 elements, the old is started dumping, more random training states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps to populate the replay memory before training starts\n",
    "initial_random_search = 20000\n",
    "replay_memory_size = 400000 # Number of states that is kept for training\n",
    "replay_memory_init_size = 40000\n",
    "batch_size = 32 # Batch size\n",
    "network_update_interval = 10000 # The frequency with which the target network is updated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSProp will be used to train the network, a very low learning rate with momentum is set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00025 # Learning rate used by RMSProp\n",
    "momentum = 0.95 # momentum used by RMSProp\n",
    "# Constant added to the squared gradient in the denominator\n",
    "# of the RMSProp update\n",
    "min_gradient = 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the trained network will be stored through time (with some checkpoints so that the training can be restarted at some partially trained state), and some information will be stored to Tensorboard, like the reward that was found and the length of a game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_path = 'saved_networks/' + env_name\n",
    "tensorboard_path = 'summary/' + env_name\n",
    "save_interval = 300000 # The frequency with which the network is saved"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network class can now be created. One instance for each network will be created. Yes, two networks are needed—one to estimate the next action to take and one to estimate the Q values or targets. From time to time, the network will be updated for action (named q_estimator here) to the target estimator (named target_estimator)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras were used in this case to build the network. It stacks three convolutional layers (without max pool layers, although some nodes are dropped to reduce the number of parameters) and then two dense layers. All of them use a relu activation later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that keras is a high-level interface. In this example, Sequential is used which means that each layer connects to the previous one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the network, a cost function can now be created and it can be fed to an optimizer. Some summary reports are also added to check the distribution of Q or loss values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator():\n",
    "    \"\"\"Q-Value Estimator neural network.\n",
    "    This network is used for both the Q-Network and the Target Network.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, scope=\"estimator\", summaries_dir=None, width=None, height=None, state_length=None, learning_rate=None, momentum=None, min_gradient=None):\n",
    "        self.scope = scope\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.epsilon = initial_epsilon\n",
    "        self.epsilon_step = (initial_epsilon - final_epsilon) / exploration_steps\n",
    "        # Writes Tensorboard summaries to disk\n",
    "        self.summary_writer = None\n",
    "        # Build the graph\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.state_length = state_length\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.min_gradient = min_gradient\n",
    "        self.build_model()\n",
    "        if summaries_dir:\n",
    "            self.summary_dir = os.path.join(summaries_dir, \"summaries_{}\".format(scope))\n",
    "            if not os.path.exists(self.summary_dir):\n",
    "                os.makedirs(self.summary_dir)\n",
    "            self.summary_writer = tf.summary.create_file_writer(self.summary_dir)\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Builds the Tensorflow graph.\n",
    "        \"\"\"\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(tf.keras.layers.Convolution2D(filters=32, kernel_size=8, strides=(4, 4), activation='relu', input_shape = (width, height, state_length), name=\"Layer1\"))\n",
    "        self.model.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=4, strides=(2, 2), activation='relu', name=\"Layer2\"))\n",
    "        self.model.add(tf.keras.layers.Convolution2D(filters=64, kernel_size=3, strides=(1, 1), activation='relu', name=\"Layer3\"))\n",
    "        self.model.add(tf.keras.layers.Flatten(name=\"Flatten\"))\n",
    "        self.model.add(tf.keras.layers.Dense(512, activation='relu', name=\"Layer4\"))\n",
    "        self.model.add(tf.keras.layers.Dense(self.num_actions, name=\"Output\"))\n",
    "        self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.learning_rate, momentum=self.momentum, epsilon=self.min_gradient)\n",
    "\n",
    "    def train_step(self, x, y, actions):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(x)\n",
    "            a_one_hot = tf.one_hot(actions, self.num_actions, 1.0, 0.0)\n",
    "            q_value = tf.math.reduce_sum(tf.math.multiply(predictions, a_one_hot), axis=1)\n",
    "            losses = tf.math.squared_difference(y, q_value)\n",
    "            loss = tf.math.reduce_mean(losses)\n",
    "        variables = self.model.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "        return predictions, losses, loss\n",
    "\n",
    "    @tf.function\n",
    "    def predict(self, s):\n",
    "        return self.model(s)\n",
    "\n",
    "    def update(self, s, a, y, global_step):\n",
    "        predictions, losses, loss = self.train_step(s, y, a)\n",
    "        if self.summary_writer:\n",
    "            with self.summary_writer.as_default():\n",
    "                tf.summary.scalar(\"loss\", loss, step=global_step)\n",
    "                tf.summary.histogram(\"loss_hist\", losses, step=global_step)\n",
    "                tf.summary.histogram(\"q_values_hist\", predictions, step=global_step)\n",
    "                tf.summary.scalar(\"max_q_value\", tf.reduce_max(predictions), step=global_step)\n",
    "        return loss\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if self.epsilon >= random.random():\n",
    "            action = random.randrange(self.num_actions)\n",
    "        else:\n",
    "            action = np.argmax(self.predict(adapt_state(state)))\n",
    "        # Decay epsilon over time\n",
    "        if self.epsilon > final_epsilon:\n",
    "            self.epsilon -= self.epsilon_step\n",
    "        return action\n",
    "\n",
    "    def get_trained_action(self, state):\n",
    "        action = np.argmax(self.predict(adapt_state(state)))\n",
    "        return action"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method is added to wrap the prediction, as it will be used in several places—firstly in an update method that will actually train this estimator. There are also two methods to retrieve an action, either with an epsilon-greedy strategy or without (after the training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model_parameters(estimator1, estimator2):\n",
    "    \"\"\"\n",
    "    Copies the model parameters of one estimator to another.\n",
    "    Args:\n",
    "    estimator1: Estimator to copy the paramters from\n",
    "    estimator2: Estimator to copy the parameters to\n",
    "    \"\"\"\n",
    "    e1_params = sorted(estimator1.trainable_variables, key=lambda v: v.name)\n",
    "    e2_params = sorted(estimator2.trainable_variables, key=lambda v: v.name)\n",
    "    update_ops = []\n",
    "    for e1_v, e2_v in zip(e1_params, e2_params):\n",
    "        op = e2_v.assign(e1_v)\n",
    "        update_ops.append(op)\n",
    "    return update_ops"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function that will be calld to update one estimator from another. This creates a set of operations that will be run later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_memory(env, state_length, replay_memory_init_size):\n",
    "    # Populate the replay memory with initial experience\n",
    "    replay_memory = deque()\n",
    "    frame = env.reset()[0]\n",
    "    state = get_initial_state(frame, state_length)\n",
    "    for i in range(replay_memory_init_size):\n",
    "        action = np.random.choice(np.arange(env.action_space.n))\n",
    "        frame, reward, done, _, _ = env.step(action)\n",
    "        next_state = np.append(state[1:, :, :], preprocess(frame), axis=0)\n",
    "        replay_memory.append(Transition(state, action, reward, next_state, done))\n",
    "        if done:\n",
    "            frame = env.reset()[0]\n",
    "            state = get_initial_state(frame, state_length)\n",
    "        else:\n",
    "            state = next_state\n",
    "    return replay_memory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates an empty replay memory. This is required so that the game can learn something. So random moves are just played for a while and hope it will make the network gain some first-hand knowledge of the game. Of course, there is also the epsilon-greedy strategy that will add new moves to the game later. This will also help a lot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_op(summary_vars, summary_inputs):\n",
    "    return [summary_vars[i].assign(summary_inputs[i]) for i in range(len(summary_vars))]\n",
    "\n",
    "def setup_summary():\n",
    "    episode_total_reward = tf.Variable(0., name=\"EpisodeTotalReward\")\n",
    "    episode_avg_max_q = tf.Variable(0., name=\"EpisodeAvgMaxQ\")\n",
    "    episode_duration = tf.Variable(0., name=\"EpisodeDuration\")\n",
    "    episode_avg_loss = tf.Variable(0., name=\"EpisodeAverageLoss\")\n",
    "    summary_vars = [episode_total_reward, episode_avg_max_q, episode_duration, episode_avg_loss]\n",
    "    summary_inputs = [tf.cast(_, tf.float32) for _ in range(len(summary_vars))]\n",
    "    update_ops = update_op(summary_vars, summary_inputs)\n",
    "    return update_ops"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the variables that is required to be visualized in Tensorboard were defined here on top of the histograms from the estimator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training, use tensorboard --logdir=summary to visualize the evolution of the training and the performance of the network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main training loop can be started by setting up the environment, estimators, and help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "env = gym.make(env_name)\n",
    "# env = gym.make(env_name, render_mode='human')\n",
    "# Create a global step variable\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "# Create estimators\n",
    "q_estimator = Estimator(env, scope=\"q\", summaries_dir=tensorboard_path, width=width, height=height, state_length=state_length, learning_rate=learning_rate, momentum=momentum, min_gradient=min_gradient)\n",
    "target_estimator = Estimator(env, scope=\"target_q\", width=width, height=height, state_length=state_length, learning_rate=learning_rate, momentum=momentum, min_gradient=min_gradient)\n",
    "copy_model = copy_model_parameters(q_estimator.model, target_estimator.model)\n",
    "update_ops = setup_summary()\n",
    "replay_memory = create_memory(env, state_length, replay_memory_init_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tensorflow process can be started and the network can be restored if there is a previous version stored in the save location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=q_estimator.optimizer, net=q_estimator.model)\n",
    "# Load a previous checkpoint if it is found\n",
    "manager = tf.train.CheckpointManager(ckpt, network_path, max_to_keep=3)\n",
    "latest_checkpoint = manager.latest_checkpoint\n",
    "if latest_checkpoint:\n",
    "    print(\"Loading model checkpoint {}...\\n\".format(latest_checkpoint))\n",
    "    ckpt.restore(latest_checkpoint)\n",
    "total_t = int(ckpt.step)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, games can be started playing. That first is done by saving the network if it is needs to be, and then the game state is set up."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is iterated forever in this game, taking an action and saving the state of this action in he replay memory. This way, when the network learns to play better, these better moves are also saved to learn them even better later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of states are obtained from the replay memory, with the reward, the action that was used, to estimate the Q value. Once this is obtained, the network is optimized to enhance its behavior. This is now where the network can be updated to play better, based on the target Q-network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the game is finished, the variables are saved to Tensorboard as well as capture a screenshot of the endgame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\robit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1332: start (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.start` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\robit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1332: start (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.start` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\robit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1383: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\robit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1383: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\robit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1383: save (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\robit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1383: save (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\robit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\profiler.py:150: maybe_create_event_file (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\robit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\profiler.py:150: maybe_create_event_file (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n",
      "  7%|▋         | 854/12000 [8:48:44<202:18:56, 65.35s/it]"
     ]
    }
   ],
   "source": [
    "for episode in tqdm(range(n_episodes)):\n",
    "    if total_t % save_interval == 0:\n",
    "        # Save the current checkpoint\n",
    "        tf.saved_model.save(q_estimator.model, network_path)\n",
    "    frame = env.reset()[0]\n",
    "    state = get_initial_state(frame, state_length)\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "    total_q_max = 0\n",
    "    tf.summary.trace_on(graph=True, profiler=True)\n",
    "    \n",
    "    for duration in itertools.count():\n",
    "        # Maybe update the target estimator\n",
    "        if total_t % network_update_interval == 0:\n",
    "            copy_model = copy_model_parameters(q_estimator.model, target_estimator.model)\n",
    "        action = q_estimator.get_action(state)\n",
    "        frame, reward, terminal, _, _ = env.step(action)\n",
    "        processed_frame = preprocess(frame)\n",
    "        next_state = np.append(state[1:, :, :], processed_frame, axis=0)\n",
    "        reward = np.clip(reward, -1, 1)\n",
    "        replay_memory.append(Transition(state, action, reward, next_state, terminal))\n",
    "        if len(replay_memory) > replay_memory_size:\n",
    "            replay_memory.popleft()\n",
    "        \n",
    "        samples = random.sample(replay_memory, batch_size)\n",
    "        states_batch, action_batch, reward_batch, next_states_batch, done_batch = map(np.array, zip(*samples))\n",
    "        # Calculate q values and targets (Double DQN)\n",
    "        adapted_state = adapt_batch_state(next_states_batch)\n",
    "        q_values_next = q_estimator.predict(adapted_state)\n",
    "        best_actions = np.argmax(q_values_next, axis=1)\n",
    "        q_values_next_target = target_estimator.predict(adapted_state)\n",
    "        targets_batch = reward_batch + np.invert(done_batch).astype(np.float32) * gamma * tf.gather_nd(q_values_next_target, indices=np.stack((np.arange(batch_size), best_actions), axis=1))\n",
    "        # Perform gradient descent update\n",
    "        states_batch = adapt_batch_state(states_batch)\n",
    "        loss = q_estimator.update(states_batch, action_batch, targets_batch, total_t)\n",
    "        total_q_max += np.max(q_values_next)\n",
    "        total_loss += loss\n",
    "        total_t += 1\n",
    "        total_reward += reward\n",
    "        if terminal:\n",
    "            break\n",
    "    stats = [total_reward, total_q_max / duration, duration, total_loss / duration]\n",
    "    update_op(update_ops, stats)\n",
    "    with q_estimator.summary_writer.as_default():\n",
    "        tf.summary.scalar('Total Reward', update_ops[0], step=episode)\n",
    "        tf.summary.scalar('Average Max Q', update_ops[1], step=episode)\n",
    "        tf.summary.scalar('Duration', update_ops[2], step=episode)\n",
    "        tf.summary.scalar('Average Loss', update_ops[3], step=episode)\n",
    "        tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=q_estimator.summary_dir)\n",
    "    env.env.ale.saveScreenPNG(six.b('./test_image_{}.png'.format(episode)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network can be trained over the 12,000 games with this final loop. For each iteration, a new action is resulted from the trained network (starting with lots of random ones) and the network is trained."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the Tensorboard graphs for the previous code:\n",
    "# ![Tensorboard](./Tensorboard.jpeg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a long time, the average Q can be seen slowly improving, although the reward stays low. It can be seen that after the training the network is a bit better, but it will still require lots of games to be good!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of the graphs displaying the evolution of the training, Tensorboard also provides a view of the graph that supports the network. It shows for instance the different weights that is used for a certain cost. If they are reused, this will be very clear from the graph."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another view available in Tensorboard when we called tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=q_estimator.summary_dir):\n",
    "# ![Graph](./Graph.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is now to try different hyper parameters. After all, it isn't known if the network will end up learning the game. For instance, adding more episodes will enhance the ability to train, but what would changing the epsilon-greedy strategy do? Or the memory size? Or simply the batch size?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb10c97395ea5cdf25b3e4cc1279b09c9151507c5eaa579e2929031795931c93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
